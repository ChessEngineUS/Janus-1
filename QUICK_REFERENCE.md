# Janus-1 Quick Reference Guide

> **TL;DR**: Real-time LLM inference at the edge with 4W power and 15.8Ã— better memory efficiency than existing solutions.

## ðŸš€ One-Minute Quickstart

### Option 1: Google Colab (Fastest)

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChessEngineUS/Janus-1/blob/main/Janus_1_Complete_Analysis.ipynb)

Click the badge above â†’ Run all cells â†’ Get complete results in ~5 minutes

### Option 2: Local Installation

```bash
git clone https://github.com/ChessEngineUS/Janus-1.git
cd Janus-1
pip install -r requirements.txt
pytest tests/ -v  # Verify installation
```

### Option 3: Python Package (Coming Soon)

```bash
pip install janus-1
```

---

## ðŸ“Š Key Numbers

| Metric | Value | Meaning |
|--------|-------|--------|
| **8.2 TOPS** | Compute | INT4/INT8 MAC operations |
| **4.05 W** | Power | Total system (compute + memory) |
| **79 mmÂ²** | Area | 3nm GAA silicon die |
| **256 MB** | Memory | On-chip KV-cache for LLMs |
| **99.99%** | Hit Rate | Cache efficiency |
| **15.8Ã—** | Efficiency | Better than Google Edge TPU |
| **1.0 cycle** | Latency | P99 read latency |

---

## ðŸ’¡ Core Concepts

### What Problem Does Janus-1 Solve?

**Problem**: Running 7B-parameter LLMs on edge devices requires:
- Massive memory bandwidth (bottleneck)
- High power consumption (>20W)
- Large die area (expensive)

**Solution**: Janus-1 co-design approach:
1. **Algorithm**: INT4 quantization (8Ã— memory reduction)
2. **Architecture**: 2-tier SRAM+eDRAM hierarchy
3. **Technology**: eDRAM for optimal power-latency-area
4. **Prefetcher**: FSM-based stream detection

**Result**: Real-time inference in <5W power envelope

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Janus-1 Processor             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Compute Fabric â”‚   Memory Hierarchy    â”‚
â”‚                 â”‚                       â”‚
â”‚  16 Tiles       â”‚  T1: 32 MB SRAM      â”‚
â”‚  (4096 MACs)    â”‚  - 4 quadrants       â”‚
â”‚  INT4/INT8      â”‚  - 4 banks each      â”‚
â”‚  8.2 TOPS       â”‚  - 1 cycle latency   â”‚
â”‚                 â”‚                       â”‚
â”‚  0.327 W        â”‚  T2: 224 MB eDRAM    â”‚
â”‚                 â”‚  - 14 banks          â”‚
â”‚                 â”‚  - 3 cycle latency   â”‚
â”‚                 â”‚                       â”‚
â”‚                 â”‚  Janus-Prefetch-1    â”‚
â”‚                 â”‚  - Stream detector   â”‚
â”‚                 â”‚  - 16-line lookahead â”‚
â”‚                 â”‚  - <2K gates         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Common Use Cases

### 1. Run Full System Simulation

```python
from src.simulator.janus_sim import JanusSim
from src.benchmarks.trace_generator import generate_llm_trace

# Generate LLM workload
trace = generate_llm_trace(context_length=2048)

# Run simulation
sim = JanusSim()
sim.run(trace)

# Get results
metrics = sim.get_metrics()
print(f"Hit Rate: {metrics.hit_rate:.2f}%")
print(f"P99 Latency: {metrics.p99_latency} cycles")
```

### 2. Calculate KV-Cache Size

```python
from src.models.kv_cache_sizing import KVCacheSizer, ModelConfig

# Configure model
config = ModelConfig(
    num_layers=32,
    hidden_dim=4096,
    context_length=4096
)

# Calculate for INT4
sizer = KVCacheSizer(config)
result = sizer.calculate('INT4')

print(f"KV-Cache: {result['size_mb']} MB")
print(f"On-chip feasible: {result['size_mb'] < 256}")
```

### 3. Compare Memory Technologies

```python
from src.models.memory_power_model import MemoryPowerModel

for tech in ['HD_SRAM', 'eDRAM', 'STT_MRAM']:
    model = MemoryPowerModel(
        cache_size_mb=224,
        bandwidth_gb_s=20,
        technology=tech
    )
    power = model.estimate_power()
    print(f"{tech}: {power['total_w']:.2f} W")
```

### 4. Optimize Prefetcher

```python
from src.simulator.janus_sim import SimulationConfig

# Sweep lookahead depths
for lookahead in [4, 8, 16, 32, 64]:
    config = SimulationConfig(prefetch_look_ahead=lookahead)
    sim = JanusSim(config)
    sim.run(trace)
    metrics = sim.get_metrics()
    print(f"LA={lookahead}: Hit={metrics.hit_rate:.2f}%")
```

---

## ðŸ“š Repository Structure

```
Janus-1/
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ simulator/              # Memory hierarchy simulator
â”‚   â”‚   â”œâ”€â”€ janus_sim.py       # Main simulator (â˜… start here)
â”‚   â”‚   â””â”€â”€ prefetcher.py      # Prefetcher FSM
â”‚   â”œâ”€â”€ models/                 # Power/area models
â”‚   â”‚   â”œâ”€â”€ kv_cache_sizing.py # Memory calculations
â”‚   â”‚   â”œâ”€â”€ memory_power_model.py
â”‚   â”‚   â””â”€â”€ thermal_analysis.py
â”‚   â””â”€â”€ benchmarks/             # Trace generation
â”‚       â””â”€â”€ trace_generator.py
â”œâ”€â”€ tests/                       # Test suite (15 tests)
â”œâ”€â”€ experiments/                 # Evaluation scripts
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ EXAMPLES.md             # Code examples (â˜… read this)
â”‚   â””â”€â”€ architecture.md
â”œâ”€â”€ Janus_1_Complete_Analysis.ipynb  # Colab notebook (â˜… try this first)
â”œâ”€â”€ README.md                    # Project overview
â”œâ”€â”€ CONTRIBUTING.md              # How to contribute
â”œâ”€â”€ CHANGELOG.md                 # Version history
â””â”€â”€ PROJECT_SUMMARY.md           # Executive summary
```

**Legend**: â˜… = Recommended starting points

---

## ðŸ”§ Configuration Options

### SimulationConfig Parameters

```python
from src.simulator.janus_sim import SimulationConfig

config = SimulationConfig(
    # Tier-1 SRAM
    t1_sram_size_mb=32,           # Total T1 capacity
    t1_sram_banks=16,             # Number of banks (4 per quad)
    t1_read_latency_cycles=1,     # Read latency
    
    # Tier-2 eDRAM
    t2_edram_banks=14,            # Number of banks
    t2_read_latency_cycles=3,     # Read latency
    
    # Cache parameters
    cache_line_size_bytes=128,    # Cache line size
    
    # Prefetcher
    prefetch_look_ahead=16,       # Lookahead depth (optimal)
    prefetch_issue_width=4,       # Max prefetches/cycle
)
```

### ModelConfig Parameters

```python
from src.models.kv_cache_sizing import ModelConfig

config = ModelConfig(
    num_layers=32,                # Transformer layers
    hidden_dim=4096,              # Model dimension
    num_heads=32,                 # Attention heads
    head_dim=128,                 # Head dimension
    context_length=4096,          # Max context tokens
)
```

---

## ðŸ“ˆ Performance Comparison

### vs. Google Edge TPU

```
Janus-1:    63 MB/W   (3nm, 4.05W)
Edge TPU:    4 MB/W   (16nm, 2W)
Advantage:   15.8Ã—    (memory efficiency)
```

### vs. NVIDIA Jetson Orin

```
Janus-1:     63 MB/W   (3nm, 4.05W)
Jetson:    <0.2 MB/W   (8nm, 15-60W)
Advantage:   315Ã—      (memory efficiency)
```

### Why Janus-1 Wins on Efficiency

1. **Specialized for memory-bound LLM inference**
2. **eDRAM technology** (1.15W for 224MB)
3. **99.99% cache hit rate** (prefetcher)
4. **INT4 quantization** (8Ã— reduction)
5. **Co-designed** (algorithm + arch + tech)

---

## ðŸŽ“ Learning Path

### Beginner (1-2 hours)

1. âœ… Read [README.md](README.md) - Overview
2. âœ… Run [Colab Notebook](https://colab.research.google.com/github/ChessEngineUS/Janus-1/blob/main/Janus_1_Complete_Analysis.ipynb) - See results
3. âœ… Review [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md) - Deep dive

### Intermediate (1 day)

4. âœ… Read [docs/EXAMPLES.md](docs/EXAMPLES.md) - Code patterns
5. âœ… Clone repo and run tests
6. âœ… Modify `experiments/run_full_system.py`
7. âœ… Run your own simulations

### Advanced (1 week)

8. âœ… Read [CONTRIBUTING.md](CONTRIBUTING.md)
9. âœ… Study source code in `src/`
10. âœ… Extend simulator with new features
11. âœ… Submit a pull request

---

## ðŸ› Troubleshooting

### Common Issues

**Issue**: Tests fail with import errors
```bash
# Solution: Install in development mode
pip install -e .
```

**Issue**: `ModuleNotFoundError: No module named 'src'`
```bash
# Solution: Run from repository root
cd Janus-1
python -m pytest tests/
```

**Issue**: Colab notebook fails to load
```bash
# Solution: Use the direct link
https://colab.research.google.com/github/ChessEngineUS/Janus-1/blob/main/Janus_1_Complete_Analysis.ipynb
```

**Issue**: Slow simulation
```python
# Solution: Reduce trace size
trace = generate_llm_trace(context_length=1024)  # Instead of 4096
```

---

## ðŸ“ Citation

If you use Janus-1 in your research, please cite:

```bibtex
@software{marena2026janus1,
  author = {Marena, Tommaso},
  title = {Janus-1: Real-Time Generative AI Acceleration at the Edge},
  year = {2026},
  url = {https://github.com/ChessEngineUS/Janus-1},
  version = {1.0.0}
}
```

---

## ðŸ”— Quick Links

| Resource | Link |
|----------|------|
| **Repository** | https://github.com/ChessEngineUS/Janus-1 |
| **Colab Notebook** | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ChessEngineUS/Janus-1/blob/main/Janus_1_Complete_Analysis.ipynb) |
| **Issues** | https://github.com/ChessEngineUS/Janus-1/issues |
| **Discussions** | https://github.com/ChessEngineUS/Janus-1/discussions |
| **Documentation** | [docs/](docs/) |
| **Examples** | [docs/EXAMPLES.md](docs/EXAMPLES.md) |
| **Contributing** | [CONTRIBUTING.md](CONTRIBUTING.md) |
| **Changelog** | [CHANGELOG.md](CHANGELOG.md) |

---

## ðŸ’¬ Getting Help

1. **Check documentation** - Most answers are in [docs/](docs/)
2. **Search issues** - Someone may have asked before
3. **Ask in discussions** - Community Q&A
4. **Open an issue** - For bugs or feature requests

---

## ðŸŒŸ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Code of conduct
- Development setup
- Coding standards
- Pull request process

**Good first issues**: Look for `good-first-issue` label

---

## ðŸ“„ License

MIT License - See [LICENSE](LICENSE) for details

---

**Made with â¤ï¸ by [@ChessEngineUS](https://github.com/ChessEngineUS)**

**Last Updated**: January 10, 2026 | **Version**: 1.0.0
